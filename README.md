# initial-transformer-arch-learning
In this repository, I am working on a very small implementation of a transformer architecture, purely for learning purposes. 

All copied from Andrey Karpathy's work for now, as I get into NLP :)

You set up the Docker container by running

`docker-compose up`

then attaching to the container and running

`python /code/v2.py`

Note: for this to work you need a CUDA gpu available, at least one, the first one is passed to the container by default.

